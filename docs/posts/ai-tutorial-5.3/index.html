<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Ai Tutorial 5.3 Image Classification &gt;2 types Cross-entropy loss 2 :: Terminal</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="My Code 
Source Code 
Cross-entropy loss 2 although softmax&#43; log Likelihood look like very suitable as a loss function.But the problem is we are using probabilities, 1&amp;gt;=p&amp;gt;=0.That mean when the model see 0.99 and 0.999, they are very close,but in another sense, 0.999 is 10 times more confident than 0.99. So, we want to transform our numbers between 0 and 1 to instead be between negative infinity and 0." />
<meta name="keywords" content=", " />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://roy989898.github.io/posts/ai-tutorial-5.3/" />




<link rel="stylesheet" href="https://roy989898.github.io/assets/style.css">

  <link rel="stylesheet" href="https://roy989898.github.io/assets/pink.css">






<link rel="apple-touch-icon" href="https://roy989898.github.io/img/apple-touch-icon-192x192.png">

  <link rel="shortcut icon" href="https://roy989898.github.io/img/favicon/pink.png">



<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Ai Tutorial 5.3 Image Classification &gt;2 types Cross-entropy loss 2">
<meta property="og:description" content="My Code 
Source Code 
Cross-entropy loss 2 although softmax&#43; log Likelihood look like very suitable as a loss function.But the problem is we are using probabilities, 1&amp;gt;=p&amp;gt;=0.That mean when the model see 0.99 and 0.999, they are very close,but in another sense, 0.999 is 10 times more confident than 0.99. So, we want to transform our numbers between 0 and 1 to instead be between negative infinity and 0." />
<meta property="og:url" content="https://roy989898.github.io/posts/ai-tutorial-5.3/" />
<meta property="og:site_name" content="Terminal" />

  <meta property="og:image" content="https://roy989898.github.io/">

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">


  <meta property="article:published_time" content="2021-05-07 11:46:30 &#43;0800 CST" />












</head>
<body class="pink">


<div class="container headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Pom&#39;s Programmer Blog
  </div>
</a>

    </div>
    
      <div class="menu-trigger">menu</div>
    
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/showcase">Showcase</a></li>
        
      
      
    

    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
      
        <li><a href="/showcase">Showcase</a></li>
      
    
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="https://roy989898.github.io/posts/ai-tutorial-5.3/">Ai Tutorial 5.3 Image Classification &gt;2 types Cross-entropy loss 2</a></h1>
  <div class="post-meta">
    
      <span class="post-date">
        2021-05-07 
      </span>
    
    
  </div>

  
  <span class="post-tags">
    
    #<a href="https://roy989898.github.io/tags/ai/">ai</a>&nbsp;
    
    #<a href="https://roy989898.github.io/tags/fastai/">fastai</a>&nbsp;
    
    #<a href="https://roy989898.github.io/tags/pytorch/">pytorch</a>&nbsp;
    
    #<a href="https://roy989898.github.io/tags/%E5%AF%AB%E7%B5%A6%E7%A8%8B%E5%BC%8F%E8%A8%AD%E8%A8%88%E5%B8%AB%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E4%BD%BF%E7%94%A8fastai%E5%92%8Cpytorch/">寫給程式設計師的深度學習：使用fastai和PyTorch</a>&nbsp;
    
    #<a href="https://roy989898.github.io/tags/cross-entropy-loss/">cross-entropy loss</a>&nbsp;
    
    #<a href="https://roy989898.github.io/tags/log/">log</a>&nbsp;
    
  </span>
  

  

  

  <div class="post-content"><div>
        <p><a href="https://colab.research.google.com/drive/1Rqum2194iz5nXH26PPoBMpKM71wQ4eYI?usp=sharing">My Code
</a></p>
<p><a href="https://colab.research.google.com/github/fastai/fastbook/blob/master/05_pet_breeds.ipynb#scrollTo=YOTrrdP7BuWd">Source Code
</a></p>
<h1 id="cross-entropy-loss-2">Cross-entropy loss 2<a href="#cross-entropy-loss-2" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<p>although softmax+ log Likelihood look like very suitable as a loss function.But the problem is we are using probabilities, 1&gt;=p&gt;=0.That mean when the model see 0.99 and 0.999, they are very close,but in another sense, 0.999 is 10 times more confident than 0.99. So, we want to transform our numbers between 0 and 1 to instead be between negative infinity and 0.Log!!!!!</p>
<h2 id="taking-the-log">Taking the Log<a href="#taking-the-log" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">plot_function(torch<span style="color:#f92672">.</span>log, min<span style="color:#f92672">=-</span><span style="color:#ae81ff">5</span>,max<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)
</code></pre></div><p><img src="/img/ai_t/t1/log.PNG" alt="log"></p>
<p>log in python</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">y <span style="color:#f92672">=</span> b<span style="color:#f92672">**</span>a
a <span style="color:#f92672">=</span> log(y,b)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">log(a<span style="color:#f92672">*</span>b) <span style="color:#f92672">=</span> log(a)<span style="color:#f92672">+</span>log(b)
</code></pre></div><p>at default, the pYtorch use e=2.718 as the log basic</p>
<p>in the Pytorch,nll_loss awsume you get the log of the softmax,so it do not the log.
softmax+log+nll_loss==log_softmax+nll_loss==nn.CrossEntropyLoss()</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># log_softmax -&gt;nll_loss,cross-entropy loss!!!!!</span>
loss_func <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()

</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">loss_func(acts, targ)
<span style="color:#75715e"># tensor(1.7790)</span>
</code></pre></div><p>same</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># same</span>
F<span style="color:#f92672">.</span>cross_entropy(acts, targ)
<span style="color:#75715e"># tensor(1.7790)</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># at default,will take all the loss mean</span>
<span style="color:#75715e"># reduction=&#39;none&#39; disable</span>
nn<span style="color:#f92672">.</span>CrossEntropyLoss(reduction<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;none&#39;</span>)(acts, targ)
</code></pre></div><p>we do some testing to prove <code>softmax+log+nll_loss==log_softmax+nll_loss==nn.CrossEntropyLoss()</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">sm_acts2 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>softmax(acts, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
sm_acts2
<span style="color:#75715e"># tensor([[0.7795, 0.2205],</span>
<span style="color:#75715e">#         [0.8902, 0.1098],</span>
<span style="color:#75715e">#         [0.1517, 0.8483],</span>
<span style="color:#75715e">#         [0.5245, 0.4755],</span>
<span style="color:#75715e">#         [0.9956, 0.0044],</span>
<span style="color:#75715e">#         [0.8464, 0.1536]])</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">torch<span style="color:#f92672">.</span>log(sm_acts2)
<span style="color:#75715e"># tensor([[-2.4908e-01, -1.5119e+00],</span>
<span style="color:#75715e">#         [-1.1630e-01, -2.2091e+00],</span>
<span style="color:#75715e">#         [-1.8857e+00, -1.6455e-01],</span>
<span style="color:#75715e">#         [-6.4534e-01, -7.4335e-01],</span>
<span style="color:#75715e">#         [-4.4367e-03, -5.4201e+00],</span>
<span style="color:#75715e">#         [-1.6675e-01, -1.8735e+00]])</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># test ,equal the above code,softmax + log</span>
sfm<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>log_softmax(acts, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
sfm
<span style="color:#75715e"># tensor([[-2.4908e-01, -1.5119e+00],</span>
<span style="color:#75715e">#         [-1.1630e-01, -2.2091e+00],</span>
<span style="color:#75715e">#         [-1.8857e+00, -1.6455e-01],</span>
<span style="color:#75715e">#         [-6.4534e-01, -7.4335e-01],</span>
<span style="color:#75715e">#         [-4.4366e-03, -5.4201e+00],</span>
<span style="color:#75715e">#         [-1.6675e-01, -1.8735e+00]])</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">F<span style="color:#f92672">.</span>nll_loss(sfm, targ, reduction<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;none&#39;</span>)
<span style="color:#75715e"># tensor([0.2491, 2.2091, 1.8857, 0.7434, 5.4201, 0.1667])</span>
</code></pre></div><h1 id="model-interpretation">Model Interpretation<a href="#model-interpretation" class="hanchor" ariaLabel="Anchor">&#8983;</a> </h1>
<p>use a confusion matrix to see where our model is doing well, and where it&rsquo;s doing badly:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#width 600</span>
interp <span style="color:#f92672">=</span> ClassificationInterpretation<span style="color:#f92672">.</span>from_learner(learn)
interp<span style="color:#f92672">.</span>plot_confusion_matrix(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>,<span style="color:#ae81ff">12</span>), dpi<span style="color:#f92672">=</span><span style="color:#ae81ff">60</span>)
</code></pre></div><p><img src="/img/ai_t/t1/pet_matrix.PNG" alt="pet_matrix"></p>
<p>too diccfcult to read</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># only show the most bad </span>
<span style="color:#75715e"># min_val 5 mean the wrong at least is 5</span>
interp<span style="color:#f92672">.</span>most_confused(min_val<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
<span style="color:#75715e"># [(&#39;Ragdoll&#39;, &#39;Birman&#39;, 9),</span>
<span style="color:#75715e">#  (&#39;american_pit_bull_terrier&#39;, &#39;staffordshire_bull_terrier&#39;, 8),</span>
<span style="color:#75715e">#  (&#39;Bengal&#39;, &#39;Egyptian_Mau&#39;, 6)]</span>
<span style="color:#75715e"># actual Egyptian_Mau ,but predict Bengal is9</span>

<span style="color:#75715e"># search at google, we can foind the they really need to classifer by a humanexpert, so it is ok</span>

</code></pre></div><p>new we have a good model,how can we make it better?</p>

      </div></div>

  
  
<div class="pagination">
    <div class="pagination__title">
        <span class="pagination__title-h">Read other posts</span>
        <hr />
    </div>
    <div class="pagination__buttons">
        
        <span class="button previous">
            <a href="https://roy989898.github.io/posts/ai-tutorial-5.4/">
                <span class="button__icon">←</span>
                <span class="button__text">Ai Tutorial 5.4 Image Classification &gt;2 types Improving Our Model</span>
            </a>
        </span>
        
        
        <span class="button next">
            <a href="https://roy989898.github.io/posts/ai-tutorial-5.2/">
                <span class="button__text">Ai Tutorial 5.2 Image Classification &gt;2 types Cross-entropy loss 1</span>
                <span class="button__icon">→</span>
            </a>
        </span>
        
    </div>
</div>

  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2021 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="https://roy989898.github.io/assets/main.js"></script>
<script src="https://roy989898.github.io/assets/prism.js"></script>







  
</div>

</body>
</html>
