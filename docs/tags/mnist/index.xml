<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MNIST on Terminal</title>
    <link>https://roy989898.github.io/tags/mnist/</link>
    <description>Recent content in MNIST on Terminal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Apr 2021 12:44:41 +0800</lastBuildDate><atom:link href="https://roy989898.github.io/tags/mnist/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ai Tutorial 4.8 The MNIST Loss Function</title>
      <link>https://roy989898.github.io/posts/ai-tutorial-4.8/</link>
      <pubDate>Wed, 28 Apr 2021 12:44:41 +0800</pubDate>
      
      <guid>https://roy989898.github.io/posts/ai-tutorial-4.8/</guid>
      <description>My Code Source Code
MNIST Loss Function some basic python zip # zip a=[1,2,3,4] b=[5,6,7,8] list(zip(a,b)) # [(1, 5), (2, 6), (3, 7), (4, 8)] create array [1]*4 # [1, 1, 1, 1] tensor([1]*4 + [0]*3) # tensor([1, 1, 1, 1, 0, 0, 0]) Some basic pytorch functions horizontal tensor to vertical tensors tensor([1]*4 + [0]*3) # tensor([1, 1, 1, 1, 0, 0, 0]) tensor([1]*4 + [0]*3).unsqueeze(1) # tensor([[1], # [1], # [1], # [1], # [0], # [0], # [0]]) torch.</description>
      <content>&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1rMfM4H92wklMLDydjnChmJMHoJ3OS6SL?usp=sharing&#34;&gt;My Code&lt;/a&gt;
&lt;a href=&#34;https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb&#34;&gt;Source Code&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;_mnist-loss-function_&#34;&gt;&lt;em&gt;MNIST Loss Function&lt;/em&gt;&lt;/h1&gt;
&lt;h2 id=&#34;some-basic-python&#34;&gt;some basic python&lt;/h2&gt;
&lt;h3 id=&#34;zip&#34;&gt;zip&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# zip&lt;/span&gt;
a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]
b&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;]
list(zip(a,b))
&lt;span style=&#34;color:#75715e&#34;&gt;# [(1, 5), (2, 6), (3, 7), (4, 8)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;create-array&#34;&gt;create array&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# [1, 1, 1, 1]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([1, 1, 1, 1, 0, 0, 0])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;some-basic-pytorch-functions&#34;&gt;Some basic pytorch functions&lt;/h2&gt;
&lt;h3 id=&#34;horizontal-tensor-to-vertical-tensors&#34;&gt;horizontal tensor to vertical tensors&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([1, 1, 1, 1, 0, 0, 0])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[1],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [1],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [1],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [1],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;torchcat&#34;&gt;torch.cat&lt;/h3&gt;
&lt;p&gt;connect two tensors together
&lt;a href=&#34;https://blog.csdn.net/qq_39709535/article/details/80803003&#34;&gt;https://blog.csdn.net/qq_39709535/article/details/80803003&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;A&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;#2x3的张量（矩阵）                                     &lt;/span&gt;
A
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[1., 1., 1.],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [1., 1., 1.],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [1., 1., 1.],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [1., 1., 1.]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;B&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
B
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[2., 2., 2.],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [2., 2., 2.],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [2., 2., 2.],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [2., 2., 2.]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;C&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cat([A,B])
C&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.Size([8, 3])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;tensorview&#34;&gt;Tensor.view&lt;/h3&gt;
&lt;p&gt;PyTorch allows a tensor to be a View of an existing tensor. View tensor shares the same underlying data with its base tensor.&lt;/p&gt;
&lt;p&gt;把原先tensor中的數據按照行優先的順序排成一個一維的數據（這裡應該是因為要求地址是連續存儲的），然後按照參數組合成其他維度的tensor。比如說是不管你原先的數據是[ [[1,2,3],[4,5,6]]]還是[1,2,3,4,5,6]，因為它們排成一維向量都是6個元素，所以只要view後面的參數一致，得到的結果都是一樣的。比如，
example&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;a&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Tensor([[[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;],[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]]])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))


&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[1., 2.],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [3., 4.],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [5., 6.]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;torchrandn&#34;&gt;torch.randn&lt;/h3&gt;
&lt;p&gt;create a list of random numberless&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([ 0.9912,  0.4679, -0.2049, -0.7409,  0.3618,  1.9199, -0.2254, -0.3417])&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn((&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[ 0.3040],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [-0.6890],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [-1.1267],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [-0.2858],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [-1.0935],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [ 1.1351],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [ 0.7592],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [-3.5945]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;matrix-multiplication&#34;&gt;matrix multiplication&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;A&lt;span style=&#34;color:#a6e22e&#34;&gt;@B&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/matrix_m.PNG&#34; alt=&#34;rt&#34;&gt;
For instance, row 1, column 2 (the orange dot with a red border) is calculated as a1,1∗b1,2+a1,2∗b2,2&lt;/p&gt;
&lt;h2 id=&#34;mnist-loss-function&#34;&gt;MNIST Loss Function&lt;/h2&gt;
&lt;h3 id=&#34;prepare-the-train-data&#34;&gt;Prepare the train data&lt;/h3&gt;
&lt;h4 id=&#34;connect-the-photo&#34;&gt;connect the photo&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;stacked_threes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.Size([6131, 28, 28])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;stacked_sevens&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.Size([6265, 28, 28])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;train_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cat([stacked_threes, stacked_sevens])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;)
train_x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.Size([12396, 784])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;the above acode,we first connect the stacked_threes(each pixel present by 0-1 number) and
for each picture , orginal is respenct by a 2d tensor,(28&lt;em&gt;28),turn to 1d tensor 784
&lt;code&gt;view(-1, 28*28)&lt;/code&gt; mean 28&lt;/em&gt;28 column,-1 mean not specific the row number,just make it can fit the content,becasue we have
&lt;code&gt;6131+6265=12396&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;add-the-tag-for-each-photo&#34;&gt;add the tag for each photo&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# assign the tag to each image&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# We need a label for each image. We&amp;#39;ll use `1` for 3s and `0` for 7s:&lt;/span&gt;
train_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;len(threes) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;len(sevens))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
train_x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape,train_y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# (torch.Size([12396, 784]), torch.Size([12396, 1]))&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# train_X,12396 images,each image total 784 pixels&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#train_y,12396 tag,because eachpicture 1 tag,1 tag inf in each tag&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;prepare-the-pytorch-need-format&#34;&gt;prepare the Pytorch need format&lt;/h4&gt;
&lt;p&gt;A Dataset in PyTorch is required to return a tuple of (x,y) when indexed. Python provides a zip function which, when combined with list, provides a simple way to get this functionality:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;dset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(zip(train_x,train_y))
x,y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dset[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape,y
&lt;span style=&#34;color:#75715e&#34;&gt;# x is  the image,t is the tag&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# (torch.Size([784]), tensor([1]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;prepare-the-valid-data&#34;&gt;Prepare the valid data&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;valid_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cat([valid_3_tens, valid_7_tens])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;)
valid_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;len(valid_3_tens) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;len(valid_7_tens))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
valid_dset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(zip(valid_x,valid_y))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;create-random-init-param&#34;&gt;create random init param&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;init_params&lt;/span&gt;(size, std&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(size)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;std)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad_()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# weneed a vertical 2d array,show we need (28*28,1),not only 28*28&lt;/span&gt;
weights &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; init_params((&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;span style=&#34;color:#75715e&#34;&gt;# weights&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The function &lt;code&gt;weights*pixels&lt;/code&gt; won&amp;rsquo;t be flexible enough—it is always equal to 0 when the pixels are equal to 0 (i.e., its &lt;em&gt;intercept&lt;/em&gt; is 0). You might remember from high school math that the formula for a line is &lt;code&gt;y=w*x+b&lt;/code&gt;; we still need the &lt;code&gt;b&lt;/code&gt;. We&amp;rsquo;ll initialize it to a random number too:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;bias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; init_params(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# why??????&lt;/span&gt;
bias
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;predict-a-image&#34;&gt;Predict a image&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;(train_x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;weights&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; bias
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;we can use a foor loop to calculate all the image pred,but this is slow&lt;br&gt;
so we use matrix multiplication  ,more fast can use GPU
we suggest you take a look at the Intro to Matrix Multiplication &lt;a href=&#34;https://www.youtube.com/watch?v=kT4Mp9EdVqs&amp;amp;ab_channel=KhanAcademy&#34;&gt;https://www.youtube.com/watch?v=kT4Mp9EdVqs&amp;amp;ab_channel=KhanAcademy&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/matrix_m.PNG&#34; alt=&#34;rt&#34;&gt;
For instance, row 1, column 2 (the orange dot with a red border) is calculated as  a1,1∗b1,2+a1,2∗b2,2&lt;/p&gt;
&lt;h3 id=&#34;predict--multi-image&#34;&gt;Predict  multi image&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;weights&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.Size([784, 1])&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;train_x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.Size([12396, 784])&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# xb@weights + bias is the formula to predict is the image is 3 or 7,1 is 3,0 is 7&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;linear1&lt;/span&gt;(xb): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; xb&lt;span style=&#34;color:#a6e22e&#34;&gt;@weights&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; bias
preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; linear1(train_x)
preds
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;corrects &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (preds&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; train_y
corrects
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[ True],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [ True],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [ True],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         ...,&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [False],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [False],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [False]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;corrects&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.49080348014831543&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;first-loss-finction&#34;&gt;first loss finction&lt;/h3&gt;
&lt;p&gt;suppose we had three images which we knew were a 3, a 7, and a 3. And suppose our model predicted with high confidence (0.9) that the first was a 3, with slight confidence (0.4) that the second was a 7, and with fair confidence (0.2), but incorrectly, that the last was a 7. This would mean our loss function would receive these values as its inputs:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 1 is 3,0 is 7&lt;/span&gt;
trgts  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
prds   &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;])

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;C/CUDA speed
具体的意思可以理解为：针对于x而言，如果其中的每个元素都满足condition，就返回x的值；如果不满足condition，就将y对应位置的元素或者y的值(如果y为氮元素tensor的话)替换x的值，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# low is good&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# low is good&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mnist_loss&lt;/span&gt;(predictions, targets):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(targets&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;predictions, predictions)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# example&lt;/span&gt;
torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(trgts&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;prds, prds)
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.where(trgts==1, 1-prds, prds)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;mnist_loss(prds,trgts)
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor(0.4333)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;better-loss-finction&#34;&gt;better loss finction&lt;/h3&gt;
&lt;p&gt;buts this mnist_loss has a problem , it assume the predict is alwasy0-1
we can use sigmoid function,it map all the value between 1 and 0&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;(x): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x))
plot_function(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid, title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sigmoid&amp;#39;&lt;/span&gt;, min&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/sig.png&#34; alt=&#34;sig&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mnist_loss&lt;/span&gt;(predictions, targets):
    predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; predictions&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(targets&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;predictions, predictions)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;why select sigmoid()? becuase it can keep the mnist_loss function
has a meaningful derivative. It can&amp;rsquo;t have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level
This requirement means that sometimes it does not really reflect exactly what we are trying to achieve, but is rather a compromise between our real goal, and a function that can be optimized using its gradient.&lt;/p&gt;
&lt;p&gt;為什麼選擇sigmoid（）？ 因為它可以保留mnist_loss函數
具有有意義的導數 它不能有較大的扁平部分和較大的跳動，而必須相當平滑。 這就是為什麼我們設計一個損失函數以響應置信度水平的微小變化的原因
此要求意味著有時它不能真正反映出我們要實現的目標，但實際上是我們實際目標與可以使用其梯度進行優化的功能之間的折衷。&lt;/p&gt;
&lt;h2 id=&#34;loss-vs-metrics&#34;&gt;Loss vs Metrics&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Metrics&lt;/code&gt;, are the numbers that we really care about. These are the values that are printed at the end of each epoch that tell us how our model is really doing.  when judging the performance of a model,we use metrics&lt;/p&gt;
&lt;p&gt;&lt;code&gt;loss&lt;/code&gt;,To drive automated learning, the loss must be a function that has a meaningful derivative. It can&amp;rsquo;t have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
