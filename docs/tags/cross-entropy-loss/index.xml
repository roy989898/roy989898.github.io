<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cross-entropy loss on Terminal</title>
    <link>https://roy989898.github.io/tags/cross-entropy-loss/</link>
    <description>Recent content in cross-entropy loss on Terminal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 May 2021 16:55:28 +0800</lastBuildDate><atom:link href="https://roy989898.github.io/tags/cross-entropy-loss/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ai Tutorial 5.2 Image Classification &gt;2 types Cross-entropy loss</title>
      <link>https://roy989898.github.io/posts/ai-tutorial-5.2/</link>
      <pubDate>Thu, 06 May 2021 16:55:28 +0800</pubDate>
      
      <guid>https://roy989898.github.io/posts/ai-tutorial-5.2/</guid>
      <description>Cross-entropy loss fastai will choose the loss based on what kind of data and model you are using. In this case we have image data and a categorical outcome, so fastai will default to using cross-entropy loss.
Cross-entropy loss can use for more than 2 category
Viewing Activations and Labels x,y = dls.one_batch() x.shape # torch.Size([64, 3, 224, 224]) our batch isze is 64,so we can see the list is 64 item.</description>
      <content>&lt;h1 id=&#34;cross-entropy-loss&#34;&gt;Cross-entropy loss&lt;/h1&gt;
&lt;p&gt;fastai will choose the loss based on what kind of data and model you are using. In this case we have image data and a categorical outcome, so fastai will default to using cross-entropy loss.&lt;/p&gt;
&lt;p&gt;Cross-entropy loss can use for more than 2 category&lt;/p&gt;
&lt;h2 id=&#34;viewing-activations-and-labels&#34;&gt;Viewing Activations and Labels&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;x,y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dls&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;one_batch()

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.Size([64, 3, 224, 224])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;our batch isze is 64,so we can see the list is 64 item.0-36,37 type&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;y
&lt;span style=&#34;color:#75715e&#34;&gt;# TensorCategory([ 7,  1,  0, 14, 19,  9,  2, 35, 12,  0, 26, 34, 18, 21,  5,  8,  0, 35,  8,  8, 28, 35, 17, 34, 21,  3, 17, 19, 18, 22,  9, 12, 34, 10, 35, 25, 13, 18, 32, 36, 20, 26,  5, 18, 31,  6,  7,  9,&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#          3,  1,  0, 30,  2,  4, 12, 24, 30,  1, 30, 20, 30, 21,  3, 12], device=&amp;#39;cuda:0&amp;#39;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;see the predict&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;preds,target &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_preds(dl&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[(x,y)])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;target
&lt;span style=&#34;color:#75715e&#34;&gt;# TensorCategory([ 7,  1,  0, 14, 19,  9,  2, 35, 12,  0, 26, 34, 18, 21,  5,  8,  0, 35,  8,  8, 28, 35, 17, 34, 21,  3, 17, 19, 18, 22,  9, 12, 34, 10, 35, 25, 13, 18, 32, 36, 20, 26,  5, 18, 31,  6,  7,  9,&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#          3,  1,  0, 30,  2,  4, 12, 24, 30,  1, 30, 20, 30, 21,  3, 12])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# preds containe 64 pred, becasue beatch size is 64,probilitiesof 37 type ,because it contain 37 type&lt;/span&gt;
preds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.Size([64, 37])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# between 0-1,&lt;/span&gt;
preds[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([2.7509e-08, 4.1222e-08, 3.7762e-06, 4.6692e-07, 6.6490e-06, 1.6953e-08, 2.9940e-05, 9.9975e-01, 1.9381e-04, 2.9978e-09, 1.0564e-08, 1.0974e-07, 3.9340e-07, 1.0617e-08, 7.8258e-09, 4.8307e-08,&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         2.9032e-07, 8.0013e-09, 2.2539e-08, 5.3139e-07, 1.7915e-08, 1.0556e-07, 3.6633e-06, 5.3050e-06, 1.2096e-07, 6.5162e-08, 4.3347e-09, 9.6756e-08, 5.2215e-06, 2.0169e-07, 1.5412e-07, 8.8911e-07,&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         2.2806e-07, 1.2523e-07, 6.1131e-09, 6.0672e-08, 3.3345e-07])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# add them all is 1&lt;/span&gt;
len(preds[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]),preds[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
&lt;span style=&#34;color:#75715e&#34;&gt;# (37, tensor(1.))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;softmax&#34;&gt;Softmax&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# if we have 6 picture,and 2 type&lt;/span&gt;
acts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn((&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
acts
&lt;span style=&#34;color:#75715e&#34;&gt;# first column is confident of the 3 ,second is the column of the 7&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[-0.9916, -2.2545],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [ 0.1560, -1.9368],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [-0.6164,  1.1047],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [-2.0798, -2.1778],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [ 1.6429, -3.7728],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [-1.2445, -2.9512]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;acts&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid()
&lt;span style=&#34;color:#75715e&#34;&gt;# we can not direct use sigmoid,because c1+c2!=1, we hope the probaility of 7 and 3 sum is 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;we can calculate the relative of the 7 and 3&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;acts[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;span style=&#34;color:#75715e&#34;&gt;# get the first column&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([-0.9916,  0.1560, -0.6164, -2.0798,  1.6429, -1.2445])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# this is first column&lt;/span&gt;
f_c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(acts[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;acts[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid()
f_c
&lt;span style=&#34;color:#75715e&#34;&gt;# second column is 1- first column softmax do this thing&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;s_c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f_c
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;softmax do this thing&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;softmax&lt;/span&gt;(x): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; exp(x) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; exp(x)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keepdim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;span style=&#34;color:#75715e&#34;&gt;# exp is e**8 ,e is 2.718&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;sm_acts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(acts, dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
sm_acts
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[0.7795, 0.2205],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.8902, 0.1098],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.1517, 0.8483],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.5245, 0.4755],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.9956, 0.0044],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.8464, 0.1536]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;softmax is the multi-category equivalent of sigmoid—we have to use it any time we have more than two categories and the probabilities of the categories must add to 1, and we often use it even when there are just two categories, just to make things a bit more consistent.&lt;br&gt;
Taking the exponential ensures all our numbers are positive, and then dividing by the sum ensures we are going to have a bunch of numbers that add up to 1. The exponential also has a nice property: if one of the numbers in our activations x is slightly bigger than the others, the exponential will amplify this (since it grows, well&amp;hellip; exponentially), which means that in the softmax, that number will be closer to 1.&lt;/p&gt;
&lt;p&gt;Intuitively, the softmax function really wants to pick one class among the others, so it&amp;rsquo;s ideal for training a classifier when we know each picture has a definite label. (Note that it may be less ideal during inference, as you might want your model to sometimes tell you it doesn&amp;rsquo;t recognize any of the classes that it has seen during training, and not pick a class because it has a slightly bigger activation score. In this case, it might be better to train a model using multiple binary output columns, each using a sigmoid activation.)&lt;/p&gt;
&lt;p&gt;Softmax is the first part of the cross-entropy loss—the second part is log likelihood.&lt;/p&gt;
&lt;p&gt;取指數可確保我們所有的數字都是正數，然後除以和可確保我們將擁有一堆加起來為1的數字。指數也具有很好的屬性：如果x中的數字之一比其他稍大一些,放大（因為它會以指數形式增長）（這是指數增長），這意味著在softmax中，該數字將接近於1。&lt;/p&gt;
&lt;p&gt;直觀上，softmax函數確實希望從其他類別中選擇一個類別，因此當我們知道每張圖片都有一個確定的標籤時，訓練分類器是理想的選擇。 （請注意，在推理過程中它可能不太理想，因為您可能希望模型有時告訴您，它無法識別訓練中看到的任何課程，並且不選一個課程，因為它的激活分數稍高在這種情況下，最好使用多個二進制輸出列訓練模型，每個輸出列都使用S型激活。）&lt;/p&gt;
&lt;h2 id=&#34;log-likelihood&#34;&gt;Log Likelihood&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# old&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mnist_loss&lt;/span&gt;(inputs, targets):
    inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; inputs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sigmoid()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(targets&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;inputs, inputs)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# tag&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 0 is7, 1 is3?????&lt;/span&gt;
targ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# these are the softmax activations:&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# left is 3,rightis 7 probility&lt;/span&gt;
sm_acts

&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([[0.7795, 0.2205],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.8902, 0.1098],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.1517, 0.8483],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.5245, 0.4755],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.9956, 0.0044],&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#         [0.8464, 0.1536]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# get the taged probility&lt;/span&gt;
idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)
sm_acts[idx, targ]
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([0.7795, 0.1098, 0.1517, 0.4755, 0.0044, 0.8464])&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# is 3? &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 0 is3, 1 is 7&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;#hide_input&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; IPython.display &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; HTML
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(sm_acts, columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;3&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;7&amp;#34;&lt;/span&gt;])
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;targ&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; targ
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;idx&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; idx
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sm_acts[range(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;), targ]
t &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;style&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hide_index()
&lt;span style=&#34;color:#75715e&#34;&gt;#To have html code compatible with our script&lt;/span&gt;
html &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_repr_html_()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;/style&amp;gt;&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
html &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;table id=&amp;#34;([^&amp;#34;]+)&amp;#34;\s*&amp;gt;&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;table &amp;gt;&amp;#39;&lt;/span&gt;, html)
display(HTML(html))


&lt;span style=&#34;color:#75715e&#34;&gt;# 3 7 targ idx loss&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.779514 0.220486 0 0 0.779514&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.890204 0.109796 1 1 0.109796&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.151727 0.848273 0 2 0.151727&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.524483 0.475517 1 3 0.475517&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.995573 0.004427 1 4 0.004427&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.846414 0.153586 0 5 0.846414&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;the above is log likehold&lt;/p&gt;
&lt;p&gt;Pytorch have a function that do the samething with the sm_acts[],but it recive negative number nll_loss&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# do the same thing of sm_acts[range(n), targ],except it takes the negative, because when applying the log afterward, we will have negative numbers&lt;/span&gt;
F&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nll_loss(sm_acts, targ, reduction&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;none&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([-0.7795, -0.1098, -0.1517, -0.4755, -0.0044, -0.8464])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
    </item>
    
  </channel>
</rss>
