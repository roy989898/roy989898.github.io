<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>stepping on Terminal</title>
    <link>https://roy989898.github.io/tags/stepping/</link>
    <description>Recent content in stepping on Terminal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Apr 2021 11:57:33 +0800</lastBuildDate><atom:link href="https://roy989898.github.io/tags/stepping/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ai Tutorial 4.7 An End-to-End SGD Example</title>
      <link>https://roy989898.github.io/posts/ai-tutorial-4.7/</link>
      <pubDate>Wed, 28 Apr 2021 11:57:33 +0800</pubDate>
      
      <guid>https://roy989898.github.io/posts/ai-tutorial-4.7/</guid>
      <description>An End-to-End SGD Example we want to find the smallest value
Some useful function craete a 0-19 torch array
time = torch.arange(0,20).float(); time # tensor([ 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.]) create randome number
# 返回一個張量，包含了從標準正態分佈（均值為0，方差為1，即高斯白噪聲）中抽取的一組隨機數。張量的形狀由參數sizes定義。 num=20 t=torch.randn(num) time_f = torch.arange(0,num).float(); time plt.scatter(time_f,t); t simulate a car speed
# simulate a car speed # torch.randn(20)*3 is some random noise time = torch.</description>
      <content>&lt;h1 id=&#34;_an-end-to-end-sgd-example_&#34;&gt;&lt;em&gt;An End-to-End SGD Example&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;we want to find the smallest value&lt;/p&gt;
&lt;h2 id=&#34;some-useful-function&#34;&gt;Some useful function&lt;/h2&gt;
&lt;p&gt;craete a 0-19 torch array&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float(); time
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;create randome number&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 返回一個張量，包含了從標準正態分佈（均值為0，方差為1，即高斯白噪聲）中抽取的一組隨機數。張量的形狀由參數sizes定義。&lt;/span&gt;
num&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;
t&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(num)
time_f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,num)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float(); time
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(time_f,t);
t
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/rt.PNG&#34; alt=&#34;rt&#34;&gt;&lt;/p&gt;
&lt;p&gt;simulate a car speed&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# simulate a car speed&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# torch.randn(20)*3 is some random noise&lt;/span&gt;
time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float(); time
speed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.75&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(time&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9.5&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(time,speed);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/car_speed.PNG&#34; alt=&#34;car_speed&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;use-sgd-to-find-the-smallest-value-for-the-loss&#34;&gt;use SGD to find the smallest value for the loss&lt;/h2&gt;
&lt;h3 id=&#34;step-0-gues-the-functions&#34;&gt;Step 0 gues the functions&lt;/h3&gt;
&lt;p&gt;we nedd to find the a,b,c that make the loss is the lowset
(time**2)+(b*time)+c&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt;(t, params):
    a,b,c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; params
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(t&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (b&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;t) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-01-define-the-meaning-of-best&#34;&gt;Step 0.1 define the meaning of best&lt;/h3&gt;
&lt;p&gt;we use a loss function to define the best, which will return a value based on a prediction and a target, where lower values of the function correspond to &amp;ldquo;better&amp;rdquo; predictions. For continuous data, it&amp;rsquo;s common to use mean squared error:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mse&lt;/span&gt;(preds, targets): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; ((preds&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;targets)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-1-set-the-apramter-as-a-randome-value&#34;&gt;Step 1 set the apramter as a randome value&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;params&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None
params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad_()
orig_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clone()
params
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-2-calculate-the-predict&#34;&gt;Step 2 calculate the predict&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; f(time, params)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;show_preds&lt;/span&gt;(preds, ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; ax &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; None: ax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots()[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(time, speed)
    &lt;span style=&#34;color:#75715e&#34;&gt;# to_npconvert tensor to numpy arry&lt;/span&gt;
    ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(time, to_np(preds), color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;red&amp;#39;&lt;/span&gt;)
    ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylim(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)

show_preds(preds)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/pred1.PNG&#34; alt=&#34;pred1&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-3-calculate-the-losses&#34;&gt;Step 3 calculate the losses&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mse(preds, speed)
loss
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor(25.1871, grad_fn=&amp;lt;SqrtBackward&amp;gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-4--know-the-gradients&#34;&gt;Step 4  know the gradients&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad
&lt;span style=&#34;color:#75715e&#34;&gt;# the a b c gradients&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# tensor([-3.1634, -0.2709, -0.3931])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step-5--step-the-weights&#34;&gt;Step 5  Step the weights&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-5&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# assign the chnaged parameter to the params&lt;/span&gt;
params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; lr &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad
params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s see if the loss has improved:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Let&amp;#39;s see if the loss has improved:&lt;/span&gt;
preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; f(time,params)
mse(preds, speed)
show_preds(preds)
&lt;span style=&#34;color:#75715e&#34;&gt;# improve a little bit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/ip.PNG&#34; alt=&#34;pred1&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step-6--repeat-it&#34;&gt;step 6 , repeat it&lt;/h3&gt;
&lt;h1 id=&#34;we-use-a-for-loop-to-do-multi-time&#34;&gt;we use a for loop to do multi time&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;apply_step&lt;/span&gt;(params, prn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True):
    preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; f(time, params)
    loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mse(preds, speed)
    loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
    params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; lr &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data
    params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; prn: &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item())
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; preds
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;): apply_step(params)

&lt;span style=&#34;color:#75715e&#34;&gt;# 160.42279052734375&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 160.14772033691406&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 159.87269592285156&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 159.59768676757812&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 159.3227081298828&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 159.04774475097656&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 158.7728271484375&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 158.4979248046875&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 158.22305297851562&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# 157.9481964111328&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;_,axs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;))
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; ax &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; axs: show_preds(apply_step(params, False), ax)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tight_layout()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/4p.PNG&#34; alt=&#34;4p&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;step7-stop&#34;&gt;Step7 stop&lt;/h3&gt;
&lt;p&gt;we do 10 round ,than stop**&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Ai Tutorial 4.6 Stepping With a Learning Rate</title>
      <link>https://roy989898.github.io/posts/ai-tutorial-4.6/</link>
      <pubDate>Wed, 28 Apr 2021 11:30:02 +0800</pubDate>
      
      <guid>https://roy989898.github.io/posts/ai-tutorial-4.6/</guid>
      <description>Stepping With a Learning Rate when we get the gradient,we cau use it calculate the new paramter . Nearly all approaches start with the basic idea of multiplying the gradient by some small number, called the learning rate (LR). The learning rate is often a number between 0.001 and 0.1, although it could be anything Often, people select a learning rate just by trying a few, and finding which results in the best model after training (we&amp;rsquo;ll show you a better approach later in this book, called the learning rate finder).</description>
      <content>&lt;h1 id=&#34;_stepping-with-a-learning-rate_&#34;&gt;&lt;em&gt;Stepping With a Learning Rate&lt;/em&gt;&lt;/h1&gt;
&lt;p&gt;when we get the gradient,we cau use it calculate the new paramter . Nearly all approaches start with the basic idea of multiplying the gradient by some small number, called the learning rate (LR). The learning rate is often a number between 0.001 and 0.1, although it could be anything Often, people select a learning rate just by trying a few, and finding which results in the best model after training (we&amp;rsquo;ll show you a better approach later in this book, called the learning rate finder). Once you&amp;rsquo;ve picked a learning rate, you can adjust your parameters using this simple function:
w -= gradient(w) * lr&lt;br&gt;
This is known as &lt;em&gt;stepping&lt;/em&gt; your parameters, using an &lt;em&gt;optimizer step&lt;/em&gt;.
當我們得到梯度時，我們就用它來計算新的參數。 幾乎所有方法都始於將梯度乘以一個稱為學習率（LR）的小數的基本思想。 學習率通常是0.001到0.1之間的數字，儘管可以是任意數。通常，人們僅通過嘗試一些就可以選擇學習率，並在訓練後發現哪種模式可以得到最佳模型（我們將在稍後向您展示一種更好的方法 在這本書中，稱為學習率查找器）。 選擇學習速度後，您可以使用以下簡單功能調整參數：
w -= gradient(w) * lr&lt;br&gt;
使用“優化步”，這稱為“步進”你的參數。&lt;/p&gt;
&lt;p&gt;if your Lr too small,maybe too slow,&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/step_small.PNG&#34; alt=&#34;sgd_step&#34;&gt;&lt;/p&gt;
&lt;p&gt;if LR too big,it can actually result in the loss getting worse,&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/strp_big1.PNG&#34; alt=&#34;sgd_step&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roy989898.github.io/img/ai_t/t1/steo_big2.PNG&#34; alt=&#34;sgd_step&#34;&gt;&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
