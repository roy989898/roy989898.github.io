+++
title = "Ai Tutorial 4.9 SGD and Mini-Batches"
date = "2021-04-28T16:06:34+08:00"
author = ""
authorTwitter = "" #do not include @
cover = ""
tags = ["ai", "fastai","pytorch","寫給程式設計師的深度學習：使用fastai和PyTorch","SGD","batch","step"]
keywords = ["", ""]
description = ""
showFullContent = false
+++

we already have a SGD loss function,we can go to `Step`  
which is to change or update the weights based on the gradients. This is called an optimization step.

# optimization step
